{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "optimizacion_usando_ElasticNet.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alemando/redesNeuronales/blob/main/notebooks/9-optimizacion_usando_ElasticNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": false,
        "id": "In5mP3wZjp2Z"
      },
      "source": [
        "Optimización usando ElasticNet\n",
        "==="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gvyt9ScmjqGB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Zz6OsZrjp2b"
      },
      "source": [
        "En esta técnica se combina la penalización de ridge regression y LASSO, tal como se indica en la siguiente ecuación:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0AKa66Cjp2c"
      },
      "source": [
        "$$ \\sum_{i=1}^N (y_i - g(x_i))^2 + \\alpha \\rho * (\\sum_{p=1} |w_p|) + \\frac{\\alpha (1 - \\rho)}{2}(\\sum_{p=1} w_p^2)$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LnAs1DOtjp2c"
      },
      "source": [
        "$\\alpha$ y $\\rho$ son hiperparámetros suministrados por el usuario. **Nota:** Para el modelo lineal, la penalización solo aplica para los coeficientes de $x$, no para el intercepto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj6JbSbkjp2d"
      },
      "source": [
        "#\n",
        "# A continuación se presenta la implementación de un modelo de\n",
        "# regresión lineal que usa la función de penalización ElasticNet \n",
        "# para estimar los parámetros óptimos. Complete el código presentado\n",
        "# para que pasen las pruebas definidas en las celdas restantes.\n",
        "#\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pytest\n",
        "\n",
        "\n",
        "class ElasticNetRegression:\n",
        "    def __init__(self, intercept, coef, maxiter, mu, alpha, rho):\n",
        "        self.intercept_ = intercept\n",
        "        self.coef_ = np.array(coef)\n",
        "        self._maxiter = maxiter\n",
        "        self._mu = mu\n",
        "        self._alpha = alpha\n",
        "        self._rho = rho\n",
        "\n",
        "    def compute_loss(self, x, y):\n",
        "        d = self.predict(x)\n",
        "        error = np.power(np.array(y) - np.array(d),2)\n",
        "        loss = (sum(error) + self._alpha * self._rho * sum(abs(self.coef_)) + \n",
        "                self._alpha*(1 - self._rho)*sum(np.power(self.coef_,2))/2)\n",
        "        return loss\n",
        "\n",
        "    def predict(self, x):\n",
        "        return [self.coef_[0]*d[0] + self.coef_[1]*d[1] + self.intercept_ for d in x]\n",
        "\n",
        "    def compute_gradient(self, x, y):\n",
        "        grd = []\n",
        "\n",
        "        error = np.array([yi - di for yi, di in zip(y, self.predict(x))])\n",
        "\n",
        "        self._grad_intercept = -2*np.sum(error)\n",
        "        \n",
        "        gSSE1 = -2*np.sum([e*i[0] for e, i in zip(error,x)])\n",
        "        PenLasso = self._alpha * self._rho * (1 if self.coef_[0] > 0 else -1)\n",
        "        PenElastic = self._alpha * (1 - self._rho) * self.coef_[0]\n",
        "        grd.append(gSSE1 + PenLasso + PenElastic)\n",
        " \n",
        "        gSSE2 = -2*np.sum([e*i[1] for e, i in zip(error,x)])\n",
        "        PenLasso = self._alpha * self._rho * (1 if self.coef_[1] > 0 else -1)\n",
        "        PenElastic = self._alpha * (1 - self._rho) * self.coef_[1]\n",
        "        grd.append(gSSE2 + PenLasso + PenElastic) \n",
        " \n",
        "        self._grad_coef = np.array(grd)\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        for iter in range(self._maxiter):\n",
        "            self.compute_gradient(x, y)\n",
        "            self.improve()\n",
        "\n",
        "    def improve(self):\n",
        "        self.intercept_ = self.intercept_ - self._mu * self._grad_intercept\n",
        "        self.coef_ = self.coef_ - self._mu * self._grad_coef\n",
        "\n",
        "\n",
        "x = [\n",
        "    [0.0, 0.1],\n",
        "    [0.2, 0.3],\n",
        "    [0.4, 0.5],\n",
        "    [0.6, 0.7],\n",
        "    [0.8, 0.9],\n",
        "    [1.0, 1.1],\n",
        "]\n",
        "\n",
        "# y = 1 x1 + 1.1 x2 + 0.2\n",
        "y = [\n",
        "    0.31,\n",
        "    0.73,\n",
        "    1.15,\n",
        "    1.57,\n",
        "    1.99,\n",
        "    2.41,\n",
        "]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTjRTejtjp2e",
        "outputId": "7eb065a3-4b0c-47de-ad8f-8f53f7423253",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#\n",
        "# Test 1\n",
        "# =============================================================================\n",
        "# Implemente la función de pérdida.\n",
        "#\n",
        "# Rta/\n",
        "# True\n",
        "#\n",
        "\n",
        "# ---->>> Evaluación ---->>>\n",
        "lr = ElasticNetRegression(\n",
        "    intercept=0.1,\n",
        "    coef=[0.2, 0.3],\n",
        "    maxiter=10000,\n",
        "    mu=0.001,\n",
        "    alpha=10,\n",
        "    rho = 10,\n",
        ")\n",
        "pytest.approx(lr.compute_loss(x, y), 0.0001) == 51.7044"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_asTyqEjp2f",
        "outputId": "5a28a83b-d99d-4c68-f152-807d91861199",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#\n",
        "# Test 2\n",
        "# =============================================================================\n",
        "# Implemente la función de pronóstico\n",
        "#\n",
        "# Rta/\n",
        "# True\n",
        "#\n",
        "\n",
        "# ---->>> Evaluación ---->>>\n",
        "lr = ElasticNetRegression(\n",
        "    intercept=0.1,\n",
        "    coef=[0.2, 0.3],\n",
        "    maxiter=10000,\n",
        "    mu=0.001,\n",
        "    alpha=10,\n",
        "    rho = 10,\n",
        ")\n",
        "all(\n",
        "    pytest.approx(a) == b\n",
        "    for a, b in zip(lr.predict(x), [0.13, 0.23, 0.33, 0.43, 0.53, 0.63])\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpKMaeVijp2g",
        "outputId": "4f407fbb-0d95-4465-dddb-307413767f41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#\n",
        "# Test 3\n",
        "# =============================================================================\n",
        "# Implemente el gradiente\n",
        "#\n",
        "# Rta/\n",
        "# True\n",
        "# True\n",
        "#\n",
        "\n",
        "# ---->>> Evaluación ---->>>\n",
        "lr = ElasticNetRegression(\n",
        "    intercept=0.1,\n",
        "    coef=[0.2, 0.3],\n",
        "    maxiter=10000,\n",
        "    mu=0.001,\n",
        "    alpha=10,\n",
        "    rho = 10,\n",
        ")\n",
        "lr.compute_gradient(x, y)\n",
        "print(lr._grad_intercept == pytest.approx(-11.76))\n",
        "print(all(pytest.approx(a) == b for a, b in zip(lr._grad_coef, [73.88 , 63.704])))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pp6Lk42_jp2h",
        "outputId": "b801b490-3a93-4b56-ebd9-092fd28f2ae8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#\n",
        "# Test 4\n",
        "# =============================================================================\n",
        "# Implemente la función fit\n",
        "#\n",
        "# Rta/\n",
        "# True\n",
        "# True\n",
        "#\n",
        "\n",
        "# ---->>> Evaluación ---->>>\n",
        "lr = ElasticNetRegression(\n",
        "    intercept=0.1,\n",
        "    coef=[0.2, 0.3],\n",
        "    maxiter=10000,\n",
        "    mu=0.001,\n",
        "    alpha=10,\n",
        "    rho = 10,\n",
        ")\n",
        "lr.fit(x, y)\n",
        "print(pytest.approx(lr.intercept_, 0.001) == 1.391750)\n",
        "print(all(pytest.approx(a, 0.001) == b for a, b in zip(lr.coef_, [0.010658, 0.057296])))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n"
          ]
        }
      ]
    }
  ]
}