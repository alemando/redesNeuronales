{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "funcion_epsilon_cuadrada_insensitiva.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alemando/redesNeuronales/blob/main/notebooks/11-funcion_epsilon_cuadrada_insensitiva.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": false,
        "id": "nMANlPmzjjku"
      },
      "source": [
        "Función epsilon cuadrada insensitiva\n",
        "==="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OMuo6t7Jjjkx"
      },
      "source": [
        "Modifique el siguiente código para encontrar los parámetros del modelo usando la función $\\epsilon$^2-insensitiva:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94tfMlPUjjky"
      },
      "source": [
        "$$\n",
        "L_\\epsilon = \n",
        "\\begin{cases}\n",
        "0, & \\text{Si } |y - f(x)| \\le \\epsilon \\\\\n",
        "(|y - f(x)| - \\epsilon)^2, & \\text{de lo contrario}\n",
        "\\end{cases}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Bqv2kZIjjk0"
      },
      "source": [
        "#\n",
        "# A continuación se presenta la implementación de un modelo de\n",
        "# regresión lineal que usa la función de penalización ElasticNet\n",
        "# para estimar los parámetros óptimos. Complete el código presentado\n",
        "# para que pasen las pruebas definidas en las celdas restantes.\n",
        "#\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pytest\n",
        "\n",
        "\n",
        "class Epsilon2Regression:\n",
        "    def __init__(self, intercept, coef, maxiter, mu, epsilon):\n",
        "        self.intercept_ = intercept\n",
        "        self.coef_ = np.array(coef)\n",
        "        self._maxiter = maxiter\n",
        "        self._mu = mu\n",
        "        self._epsilon = epsilon\n",
        "\n",
        "    def compute_loss(self, x, y):\n",
        "        d = self.predict(x)\n",
        "        error = np.array([abs(yi - di) for yi, di in zip(y, d)])\n",
        "        loss = sum([(e  - self._epsilon)**2 if e > self._epsilon else 0 for e in error])\n",
        "        return loss\n",
        "\n",
        "    def predict(self, x):\n",
        "        return [self.coef_[0]*d[0] + self.coef_[1]*d[1] + self.intercept_ for d in x]\n",
        "\n",
        "    def compute_gradient(self, x, y):\n",
        "        grd = []\n",
        "        delta = 0.0001\n",
        "        W = [self.coef_[0], self.coef_[1], self.intercept_]\n",
        "        L0 = self.compute_loss(x,y)\n",
        "        for i in range(len(W)):\n",
        "          W[i] += delta\n",
        "          deltaD = [W[0]*i[0] + W[1]*i[1] + W[2] for i in x]\n",
        "          errorD = [abs(yi - di) for yi, di in zip(y, deltaD)]\n",
        "          L = sum([(e  - self._epsilon)**2 if e > self._epsilon else 0 for e in errorD])\n",
        "          grd.append((L-L0)/delta)\n",
        "          W[i] -= delta\n",
        "        self._grad_coef = np.array([grd[0], grd[1]])\n",
        "        self._grad_intercept = grd[2]\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        for iter in range(self._maxiter):\n",
        "            self.compute_gradient(x, y)\n",
        "            self.improve()\n",
        "\n",
        "    def improve(self):\n",
        "        self.intercept_ = self.intercept_ - self._mu * self._grad_intercept\n",
        "        self.coef_ = self.coef_ - self._mu * self._grad_coef\n",
        "\n",
        "\n",
        "x = [\n",
        "    [0.0, 0.1],\n",
        "    [0.2, 0.3],\n",
        "    [0.4, 0.5],\n",
        "    [0.6, 0.7],\n",
        "    [0.8, 0.9],\n",
        "    [1.0, 1.1],\n",
        "]\n",
        "\n",
        "# y = 1 x1 + 1.1 x2 + 0.2\n",
        "y = [\n",
        "    0.31,\n",
        "    0.73,\n",
        "    1.15,\n",
        "    1.57,\n",
        "    1.99,\n",
        "    2.41,\n",
        "]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEOWyqhWjjk2",
        "outputId": "4111df71-b1ea-4571-8294-9c4b1b91955e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#\n",
        "# Test 1\n",
        "# =============================================================================\n",
        "# Implemente la función de pérdida.\n",
        "#\n",
        "# Rta/\n",
        "# True\n",
        "#\n",
        "\n",
        "# ---->>> Evaluación ---->>>\n",
        "lr = Epsilon2Regression(\n",
        "    intercept=0.1,\n",
        "    coef=[0.2, 0.3],\n",
        "    maxiter=10000,\n",
        "    mu=0.001,\n",
        "    epsilon=0.1,\n",
        ")\n",
        "pytest.approx(lr.compute_loss(x, y), 0.0001) == 6.4384"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKtCuvj3jjk2",
        "outputId": "56d2b7ba-4d40-4261-8dde-09efbad10292",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#\n",
        "# Test 2\n",
        "# =============================================================================\n",
        "# Implemente la función de pronóstico\n",
        "#\n",
        "# Rta/\n",
        "# True\n",
        "#\n",
        "\n",
        "# ---->>> Evaluación ---->>>\n",
        "lr = Epsilon2Regression(\n",
        "    intercept=0.1,\n",
        "    coef=[0.2, 0.3],\n",
        "    maxiter=10000,\n",
        "    mu=0.001,\n",
        "    epsilon=0.1,\n",
        ")\n",
        "all(\n",
        "    pytest.approx(a) == b\n",
        "    for a, b in zip(lr.predict(x), [0.13, 0.23, 0.33, 0.43, 0.53, 0.63])\n",
        ")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3YAomn7jjk3",
        "outputId": "5bb8ed92-9de2-4685-d9dc-67849660e6c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#\n",
        "# Test 3\n",
        "# =============================================================================\n",
        "# Implemente el gradiente\n",
        "#\n",
        "# Rta/\n",
        "# True\n",
        "# True\n",
        "#\n",
        "\n",
        "# ---->>> Evaluación ---->>>\n",
        "lr = Epsilon2Regression(\n",
        "    intercept=0.1,\n",
        "    coef=[0.2, 0.3],\n",
        "    maxiter=10000,\n",
        "    mu=0.001,\n",
        "    epsilon=0.1,\n",
        ")\n",
        "lr.compute_gradient(x, y)\n",
        "\n",
        "print(lr._grad_intercept == pytest.approx(-10.559999 , 0.001))\n",
        "print(all(pytest.approx(a, 0.001) == b for a, b in zip(lr._grad_coef, [-7.52 , -8.576])))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jUEhlSajjk4",
        "outputId": "7b523e9a-45c4-41ee-870a-7fe42c51b338",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#\n",
        "# Test 4\n",
        "# =============================================================================\n",
        "# Implemente la función fit\n",
        "#\n",
        "# Rta/\n",
        "# True\n",
        "# True\n",
        "#\n",
        "\n",
        "# ---->>> Evaluación ---->>>\n",
        "lr = Epsilon2Regression(\n",
        "    intercept=0.1,\n",
        "    coef=[0.2, 0.3],\n",
        "    maxiter=3000,\n",
        "    mu=0.01,\n",
        "    epsilon=0.1,\n",
        ")\n",
        "lr.fit(x, y)\n",
        "print(pytest.approx(lr.intercept_, 0.001) == 0.308955)\n",
        "print(all(pytest.approx(a, 0.001) == b for a, b in zip(lr.coef_, [0.889552, 1.010447])))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n"
          ]
        }
      ]
    }
  ]
}