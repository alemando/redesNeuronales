{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "interpreter": {
      "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "optimizacion_usando_LASSO.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alemando/redesNeuronales/blob/main/notebooks/8-optimizacion_usando_LASSO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": false,
        "id": "3wRDEV_cja7H"
      },
      "source": [
        "Optimización usando LASSO\n",
        "==="
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCN2HXl1ja7K"
      },
      "source": [
        "En esta técnica, el término de penalización es el valor absoluto de los coeficientes del modelo de regresión.\n",
        "\n",
        "$$ \\sum_{i=1}^N (y_i -  g(x_i))^2 + \\alpha \\sum_{p=1}^P ||w_p|| $$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HHiaSRrja7L"
      },
      "source": [
        "$\\alpha$ es un hiperparámetro suministrado por el usuario. **Nota:** Para el modelo lineal, la penalización solo aplica para los coeficientes de $x$, no para el intercepto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j0hLtanZja7L"
      },
      "source": [
        "#\n",
        "# A continuación se presenta la implementación de un modelo de\n",
        "# regresión lineal que usa la función de penalización LASSO para\n",
        "# estimar los parámetros óptimos. Complete el código presentado\n",
        "# para que pasen las pruebas definidas en las celdas restantes.\n",
        "#\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pytest\n",
        "\n",
        "\n",
        "class LassoRegression:\n",
        "    def __init__(self, intercept, coef, maxiter, mu, alpha):\n",
        "        self.intercept_ = intercept\n",
        "        self.coef_ = np.array(coef)\n",
        "        self._maxiter = maxiter\n",
        "        self._mu = mu\n",
        "        self._alpha = alpha\n",
        "\n",
        "    def compute_loss(self, x, y):\n",
        "        d = [self.coef_[0]*d[0] + self.coef_[1]*d[1] + self.intercept_ for d in x]\n",
        "        error = np.power(np.array(y) - np.array(d),2)\n",
        "        loss = sum(error) + self._alpha * sum(abs(self.coef_))\n",
        "        return loss\n",
        "\n",
        "    def predict(self, x):\n",
        "        return [self.coef_[0]*d[0] + self.coef_[1]*d[1] + self.intercept_ for d in x]\n",
        "\n",
        "    def compute_gradient(self, x, y):\n",
        "        grd = []\n",
        "        error = np.array([yi - di for yi, di in zip(y, self.predict(x))])\n",
        "        self._grad_intercept = -2*np.sum(error)\n",
        "        \n",
        "\n",
        "        gSSE_coef1 = -2*np.sum([e*i[0] for e, i in zip(error,x)])\n",
        "        penalizacion = self._alpha * (1 if self.coef_[0] > 0 else -1)\n",
        "        grd.append(gSSE_coef1 + penalizacion)\n",
        " \n",
        "        gSSE_coef2 = -2*np.sum([e*i[1] for e, i in zip(error,x)])\n",
        "        penalizacion = self._alpha * (1 if self.coef_[1] > 0 else -1)\n",
        "        grd.append(gSSE_coef2 + penalizacion) \n",
        " \n",
        "        self._grad_coef = np.array(grd)\n",
        "\n",
        "    def fit(self, x, y):\n",
        "        for iter in range(self._maxiter):\n",
        "            self.compute_gradient(x, y)\n",
        "            self.improve()\n",
        "\n",
        "    def improve(self):\n",
        "        self.intercept_ = self.intercept_ - self._mu * self._grad_intercept\n",
        "        self.coef_ = self.coef_ - self._mu * self._grad_coef\n",
        "\n",
        "\n",
        "x = [\n",
        "    [0.0, 0.1],\n",
        "    [0.2, 0.3],\n",
        "    [0.4, 0.5],\n",
        "    [0.6, 0.7],\n",
        "    [0.8, 0.9],\n",
        "    [1.0, 1.1],\n",
        "]\n",
        "\n",
        "# y = 1 x1 + 1.1 x2 + 0.2\n",
        "y = [\n",
        "    0.31,\n",
        "    0.73,\n",
        "    1.15,\n",
        "    1.57,\n",
        "    1.99,\n",
        "    2.41,\n",
        "]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZAvgML6ja7N",
        "outputId": "1d64c06a-fec8-4833-c801-f6849a5d1e9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#\n",
        "# Test 1\n",
        "# =============================================================================\n",
        "# Implemente la función de pérdida.\n",
        "#\n",
        "# Rta/\n",
        "# True\n",
        "#\n",
        "\n",
        "# ---->>> Evaluación ---->>>\n",
        "lr = LassoRegression(\n",
        "    intercept=0.1,\n",
        "    coef=[0.2, 0.3],\n",
        "    maxiter=10000,\n",
        "    mu=0.001,\n",
        "    alpha=100,\n",
        ")\n",
        "\n",
        "pytest.approx(lr.compute_loss(x, y), 0.0001) == 57.5544"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lWV7xn6ja7N",
        "outputId": "f119ee20-98c5-4bef-c9e2-6b8d6680693d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#\n",
        "# Test 2\n",
        "# =============================================================================\n",
        "# Implemente la función de pronóstico\n",
        "#\n",
        "# Rta/\n",
        "# True\n",
        "#\n",
        "\n",
        "# ---->>> Evaluación ---->>>\n",
        "lr = LassoRegression(\n",
        "    intercept=0.1,\n",
        "    coef=[0.2, 0.3],\n",
        "    maxiter=10000,\n",
        "    mu=0.001,\n",
        "    alpha=100,\n",
        ")\n",
        "\n",
        "all(\n",
        "    pytest.approx(a) == b\n",
        "    for a, b in zip(lr.predict(x), [0.13, 0.23, 0.33, 0.43, 0.53, 0.63])\n",
        ")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-OBvD-Yja7O",
        "outputId": "9aa51f46-7a67-44e5-d583-e5e7e26f787d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#\n",
        "# Test 3\n",
        "# =============================================================================\n",
        "# Implemente el gradiente\n",
        "#\n",
        "# Rta/\n",
        "# True\n",
        "# True\n",
        "#\n",
        "\n",
        "# ---->>> Evaluación ---->>>\n",
        "lr = LassoRegression(\n",
        "    intercept=0.1,\n",
        "    coef=[0.2, 0.3],\n",
        "    maxiter=10000,\n",
        "    mu=0.001,\n",
        "    alpha=100,\n",
        ")\n",
        "lr.compute_gradient(x, y)\n",
        "\n",
        "print(lr._grad_intercept == pytest.approx(-11.76))\n",
        "print(all(pytest.approx(a) == b for a, b in zip(lr._grad_coef, [91.88 , 90.704])))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR3aUvZIja7P",
        "outputId": "af9a4241-5710-458f-bcd7-f35020107c83",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#\n",
        "# Test 4\n",
        "# =============================================================================\n",
        "# Implemente la función fit\n",
        "#\n",
        "# Rta/\n",
        "# True\n",
        "# True\n",
        "#\n",
        "\n",
        "# ---->>> Evaluación ---->>>\n",
        "lr = LassoRegression(\n",
        "    intercept=0.1,\n",
        "    coef=[0.2, 0.3],\n",
        "    maxiter=1000,\n",
        "    mu=0.001,\n",
        "    alpha=100,\n",
        ")\n",
        "lr.fit(x, y)\n",
        "print(pytest.approx(lr.intercept_, 0.001) == 1.356084)\n",
        "print(all(pytest.approx(a, 0.001) == b for a, b in zip(lr.coef_, [-0.045481 , -0.019872])))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n"
          ]
        }
      ]
    }
  ]
}